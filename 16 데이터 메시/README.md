# 16장 데이터 메시

### Intro

- 지금까지 우리는 이 책에서 OLTP 시스템을 구축하기 위해 사용되는 모델에 대해 논의했습니다.
- 실시간 데이터 모델 OLTP (Online Transactional Processing) 과 분석 모델 OLAP (Online Analytical Processing)
- 분석 데이터 관리 아키텍처 (데이터 메시)와 전통적 OLAP의 데이터 관리와 접근 방식의 차이
---
## 분석 데이터 모델 vs  트랜잭션 데이터 모델

**분석 데이터란**
회사에 축적된 데이터를 활용해 아래와 같은 인사이트를 얻을 수 있는 지식
- 비즈니스를 최적화 하는 방법에 대한 통찰
- 고객의 요구사항을 더 잘 이해
- Machine learning 모델 훈련을 통해 자동으로 의사결정을 내릴 수 있는 힘

**OLTP** **실시간 데이터 모델**
- 시스템의 비즈니스 도메인에 속한 다양한 엔티티를 중심으로 구축
- 이들의 수명주기를 구현, 상호작용 조율
- 이의 스키마는 실시간 데이터 처리 시스템을 위한 것이므로 실시간 비즈니스 트랜잭션을 지원하도록 최적화 해야한다.

**OLAP 분석 모델**
- 실시간 데이터 처리 시스템에 대한 **통찰을 제공**
- 목표
    - 실시간 트랜잭션 구현 대신 비즈니스 활동의 성과에 대한 통찰을 제공하는 것
    - 더 많은 비즈니스 가치를 얻도록 운영을 최적화하는 방법 제공

--- 
## 분석 모델 요소 - 팩트 테이블과 디멘전 테이블
### 팩트 테이블

**팩트란**
- 이미 발생한 비즈니스 활동

**팩트 테이블**
예시:
- 회사의 지원 데스크에서 해결한 사례의 기록을 담는 팩트 테이블
- PK: caseId, FK: agentKey, categoryKey, openedOnDateKey, ... customerKey

**도메인 이벤트와의 차이**
- 과거 시제의 동사로 팩트를 명명하도록 요구하지 않는다.
- 팩트 레코드는 절대로 삭제되거나 수정되지 않는다.

**분석 데이터**
- 분석 데이터는 추가만 가능한 데이터
- 현재 데이터가 만료됐다는 표현의 유일한 방법도 새로운 레코드를 추가하는 것.

**OLAP과 OLTP 모델의 차이**
- 데이터의 세분화 정도
    - 실시간 모델: 비즈니스 트랜잭션을 다루기 위해 가장 정밀한 데이터 필요
    - 분석 모델: 데이터를 취합하는 것이 다양한 유스케이스에 더 효과적
        - 데이터 분석가에 의해 데이터 크기 결정:
            -  30분마다 snapshot 생성
            -  변경이 측정될 때 마다 팩트 레코드 생성 - 낭비 또는 기술적으로 불가능

### 디멘전 테이블

**팩트 vs 디멘전**

팩트: 비즈니스 절차 또는 동작 표현 (동사)

디멘전: 팩트를 묘사 (형용사)
- 팩트의 속성을 설명하도록 고안.
- 팩트 테이블의 FK로 디멘전 테이블 참조
- 다양한 팩트 레코드에서 반복되는 모든 측정 또는 데이터; 단일 컬럼에 부적합.
- 디멘전을 통해 팩트를 확장

[star schema]

**정규화**

위의 스키마와 같이 같이 디멘전 스키마는 고도로 정규화 되어야한다.
- 분석 시스템에서 데이터 분석가에게 유연한 질의를 지원해야 하기 때문
- 비즈니스 요구사항을 지원하는 실시간 모델은 질의 예상 가능, 그러나 분석 모델의 질의 패턴은 예측할 수 없다.
- 그 결과, 정규화를 통해 동적인 질의 및 필터링 지원, 다양한 디멘전에 걸친 팩트 테이블에 대한 그룹화 지원 


### 분석 모델 - 스타, 스노우플레이크 스키마

**스타 스키마**
- 팩트와 디멘전의 관계: 다대일
- 각 디멘전 레코드는 여러 팩트에서 사용된다.
- 단일 팩트의 외부 키들은 각기 하나의 디멘전 레코드를 가리킨다.

**스노우플레이크 스키마**
- 각 디멘전을 더 작은 세밀한 디멘전으로 정규화
- Pros: 더 작은 공간에 디멘전 데이터를 저장 ; 쉬운 유지보수
- Cons: 팩트 데이터 조회 시 더 많은 테이블 조인 - 더 많은 컴퓨팅 자원 필요

두 스키마 모두 데이터 분석가가 비즈니스 성과를 분석하고 무엇을 최적화할지에 대한 통찰을 얻게하며 BI 리포트를 만들 수 있게 한다.

---
## 분석 데이터 관리 플랫폼
이제 데이터를 생성하고 분석 데이터를 제공하는 데이터 관리 아키텍처에 대해 알아보자.

데이터 웨어하우스와 데이터 레이크, 두가지의 종류가 있다.

두 아키텍처의 기본적 작동 원리와 차이점, 각 접근 방식의 어려운 점에 대해 알아보자.
이는 데이터 메시 패러다임과 도메인 주도 설계와의 상호작용을 논의하는데 기초가 된다.

### 데이터 웨어하우스 [p266]
**프로세스**
1. 기업의 모든 실시간 데이터 처리 시스템에서 데이터 추출
2. 분석 모델로 변환
3. 분석 지향 데이터베이스에 적재; 데이터베이스 == 데이터 웨어하우스.

- 데이터 관리 아키텍처는 기본적으로 ETL 스크립트를 기반으로 한다.
- 데이터의 원천
    - 실시간 데이터 처리 데이터베이스
    - 스트림 이벤트
    - 로그

- 변환 단계
    - 원천 데이터를 팩트/디멘전 기반 모델로 변환
    - 민감한 데이터, 중복 레코드 삭제
    - 이벤트의 순서 조정 및 작은 크기의 이벤트 합치기
    - 스테이징 영역: 변환할 때 유입되는 데이터를 저장하는 임시 저장소

**도전과제**
- 데이터 웨어하우스 아키텍처 : 엔터프라이즈 전반의 모델을 구축하는 목표
- 모델은 기업의 모든 시스템에서 생성되는 데이터를 묘사, 다양한 분석 데이터의 사용 사례를 다뤄야 한다.
    - 분석 모델의 범용성에 대해 생각해보라.  (분석 데이터 부분 참고)
- 하지만 이는 작은 규모의 조직에서 실용적이지 못하며 리포트를 구축하거나 ML 모델을 훈련하는 등 당면한 과제를 위한 모델의 설계가 훨씬 효과적이고 확장 가능한 접근 방식이다.

### 데이터 마트
- 모든 상황을 아우르는 모델을 구축하는 것을 부분적으로 해결하기 위한 방안
- 잘 정의된 분석 요구사항에 맞춰 관련된 데이터를 저장하는 데이터베이스
    - ETL 프로세스가 실시간 데이터 처리 시스템으로부터 직접 추출하는 마트
    - 데이터 웨어하우스에서 데이터를 추출하는 마트
- 문제점:결과 모델을 구현할 때 여러 부서를 아우르는 다양한 마트에서 데이터를 조회해야 함 -> 여러 데이터베이스에 걸친 질의 -> 성능 영향

**데이터 웨어하우스의 단점**
- ETL 프로세스가 분석 시스템과 실시간 데이터 처리 시스템 간 강력한 결합을 만든다.
    - 실시간 데이터 처리 세스템의 데이터베이스로부터 데이터를 가져오는 경우, 내부적으로 구현된 상세 스키마를 사용
    - 스키마가 바뀔 경우 ETL 스크립트가 작동하지 않음
    - 다소 떨어진 OLAP, OLTP 조직간의 마찰, 커뮤니케이션 어려움 야기
---
### 데이터 레이크
- 데이터 웨어하우스 아키텍처의 단점을 해결
- 닮은점
    - 데이터 웨어하우스와 같이 실시간 데이터 처리 시스템의 데이터를 유입하고 분석 모델로 변환하는 동일한 개념에 기반
- 차이점
    - 실시간 데이터 처리 시스템으로부터 데이터를 받고 바로 분석 모델로 변환하는게 아닌 원본 형태의 데이터 모델로 보관
    - 데이터 엔지니어는 데이터 레이크의 데이터를 이해하고 분석하는 ETL 스크립트를 구현, 이를 데이터 웨어하우스에 제공
- 특징
    - 실시간 데이터는 원본 형태로 먼저 저장되고 나중에 변환됨 -> 여러가지 작업 지향 분석 모델 작동이 가능
    - 리포팅, ML훈련 등 목적에 따른 다른 모델 사용 가능
- 단점
    - 다양한 버전의 실시간 데이터 모델을 수용하기 위해 동일한 ETL 스크립트를 여러 버전으로 구현/지원.
    - 시스템 복잡성 증가
    - 스키마를 강제하지 않으며 수싲 데이터의 품질을 제어하지 않는다.

---
### 데이터 웨어하우스와 데이터 레이크 아키텍처의 한계
- 분석을 위한 데이터가 많을수록 더 많은 통찰을 얻을 수 있지만, 두 방법 모두 데이터의 방대한 규모로 인해 유명무실해진다.
- 실시간 데이터 모델을 분석 모델로 변환 시 유지보수가 어려운 대규모의 임시방편 ETL 스크립트를 양산
- 실시간 데이터 처리 시스템의 경계를 침범해 구현 상세에 대한 의존성 생성
- 이와 같은 결합도는 ETL의 작업이 깨지지 않도록 실시간 데이터 모델에 대한 변경을 막는 지경까지 갈 수 있다.
- 또한 데이터 엔지니어는 비즈니스 도메인 지식이 부족하다.
- 구현 모델의 결합은 비즈니스 도메인의 모델을 지속해서 개선하고 발전하는게 흔한 DDD에서 문제가 심하다.
- 실시간 데이터 모델의 변경은 분석 모델에 예측할 수 없는 결과를 만들고, 이는 팀 간의 마찰을 유발하기도 한다.
- 해결 방안 -> 데이터 메시의 탄생


---
## 데이터 메시
- 분석 데이터를 위한 도메인 주도 설계
- 분석 데이터에 대한 모델과 소유 경계를 정의하고 프로젝션
- 데이터 품질에 대한 책임이 가장 중요한 관심사
- 4가지 핵심 원칙에 기반

### 1. 도메인 기준의 데이터 분리
- 기존 데이터 웨어하우스/레이크의 접근 방식:
    - 엔터프라이즈의 모든 데이터를 하나의 큰 모델로 통합하는 것이 목표
    - 결과 분석 모델 == 실시간 데이터 모델이라 효과적이지 X
    - 모든 시스템의 데이터를 수집해 하나의 장소에 넣어 데이터 요소의 소유권 경계를 흐림
- 데이터 메시
    - 모놀리식 분석 모델 대신 원천 데이터에 분석 모델을 일치시켜 데이터를 사용 -> 여러 분석 모델 사용 가능 (3장)
    - 분석 모델의 소유권 경계를 바운디드 컨텍스트의 경계와 일치시킬 수 있다.
    - 분석 데이터의 생성은 자연스레 관련 제품 팀에서 담당. [p271]
- 결과: 각 바운디드 컨텍스트는 자신의 OLTP 모델과 OLAP 모델을 소유한다.


### 2. 제품 관점에서 데이터 다루기
- 기존 모델: 양질의 분석 데이터를 찾고 가져오는데 어려움 존재 (특히 데이터 레이크)
- 분석 시스템이 의심스러운 원천 (내부 DB, log파일 등)에서 실시간 데이터를 가져오는 대신 바운디드 컨텍스트가 잘 정의된 **출력 포트**를 통해 분석 데이터를 제공
    - -> 분석 데이터를 사용자에게 노출하는 다양한 데이터 엔드포인트 제공

- 분석 데이터는 통상적인 퍼블릭 API와 동일하게 취급되어야 한다.
    - 필요한 엔드포인트인 데이터 출력 포트를 쉽게 찾을 수 있어야 한다.
    - 분석 엔드포인트는 제공하는 데이터와 형식을 설명하는 잘 정의된 스키마를 가져야 한다.
    - 분석 데이터는 신뢰할 수 있어야하고, 서비스 수준 계약을 정의하고 모니터링해야 한다.
    - 일반적인 API처럼 버전 관리를 하고 그에 따라 모델에서 연동을 망가뜨리는 변경을 관리해야한다.

- 분석 데이터는 제품 관점에서 제공된다.
    - 도출된 결과 모델에 사용자의 요구사항이 반영되도록 보장해야 한다.

분산 데이터 관리 아키텍처의 목표
- 1. 조직의 데이터 분석 요건을 충족할 수 있도록 작은 분석 모델이 엮일 수 있게 하는 것
    - e.g) BI 리포트가 다양한 바운디드 컨텍스트로부터 얻는 데이터를 반영해야 한다면 필요에 따라 분석 데이터를 쉽게 가져오고 로컬 변환을 적용하며 리포트를 생성할 수 있어야 한다.
- 2. 사용자마다 여러 형태의 분석 데이터가 필요한 경우를 충족
    - e.g) SQL 질의 실행을 선호하는 사용자 또는 객체 저장소로부터 데이터를 가져오는걸 선호
    - 다양한 사용자의 요구사항을 충족하는 여러 형태의 데이터를 제공하도록 다양한 언어 제공 필요

### 3. 자율성 활성화
- 제품 팀은 자신의 데이터 제품을 만들거나
- 다른 바운디드 컨텍스트에서 제공하는 데이터 제품도 사용할 수 있고,
- 데이터 제품은 상호운용이 가능해야 한다.

- 또한 분석 데이터를 제공하기 위해 각 팀이 자신의 솔루션을 구축하는것은 소모적이며 연동이 어렵다.
- 이를 방지하기 위해 플랫폼이 상호운용이 가능한 데이터 제품의 구축,실행,유지보수의 복잡성을 추상화해야 한다.
- 이를 담당하는 Data infrastructure platform team은 데이터 제품의 청사진, 단일화된 접근 패턴, 접근 제어, 제품 팀이 사용할 다양한 저장소 정의 및 플랫폼을 모니터링해 SLA와 목적을 만족하는지 보장할 책임이 있다.

### 4. 에코시스템 구축
- 데이터 메시 시스템의 마지막 단계:
    - 분석 데이터 도메인 관점에서 상호운용과 에코시스템을 가능하게 할 기구를 임명하는 것

구성원
- 바운디드 컨텍스트의 데이터 및 제품 소유자
- 데이터 인프라스트럭처 플랫폼 팀의 대표

거버넌스 그룹의 책임
- 상호운용이 가능한 에코시스템을 보장하는 규칙을 정의할 책임
- 이 규칙을 모든 데이터 제품과 그 인터페이스에 적용되게 하는 책임
- 전사적으로 이 규칙을 따르도록 보장할 책임

---
## 데이터 메시와 도메인 주도 설계 엮기
- 데이터 메시 아키텍처가 DDD 설계와 동일한 추론에 근거한다는 증거
    - 경계를 정의하도록 강조하고,
    - 잘 정의된 출력 포트 뒤에 있는 구현의 상세 내용을 감추는 것

**도움을 주는 도메인 주도 설계 패턴**
1. 유비쿼터스 언어와 결과 도메인 지식
    - 이는 분석 모델 설계를 위한 필수 요소이다.
    - 전통적인 데이터 웨어하우스, 데이터 레이크에서는 도메인 지식이 부족
2. 오픈 호스트 패턴
    - 자신의 실시간 데이터 모델과 다른 모델로 바운디드 컨텍스트 데이터를 노출하는 것은 오픈 호스트 패턴이다.
    - 분석 모델 == 부가적인 공표된 언어
3. CQRS 패턴
    - 동일한 데이터에 대한 여러 모델을 쉽게 생성하게 해준다.
    - 실시간 데이터 모델을 다양한 버전의 분석 모델로 변환하거나 제공하는것을 쉽게 해준다.
4. 파트너십 패턴
    - 서로 다른 제품을 담당하는 두 팀은 이를 적용해 각자의 분석 모델을 발전시킬 수 있다.
    - 충돌 방지 계층, 분리형 노션 패턴
